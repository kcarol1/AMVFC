# Anchor-guided multi-view fuzzy clustering for hyperspectral and LiDAR images

This repository provides the official implementation of the paper:

> **Anchor-guided multi-view fuzzy clustering for hyperspectral and LiDAR images**



---

## üîç Abstract

Multimodal remote sensing data, such as hyperspectral and LiDAR imagery, provide complementary information for land cover analysis. However, effectively clustering these heterogeneous yet spatially aligned data remains challenging due to cross-modal inconsistency and data complexity. In this work, we propose an anchor-guided multi-view fuzzy clustering (AMVFC) framework to achieve robust and consistent clustering across multiple modalities. The proposed approach represents cluster structures through a set of anchor points and incorporates a shared fuzzy membership to promote cross-modal consistency, while preserving the characteristics of each modality. Furthermore, a deep extension of the framework is developed to better capture nonlinear relationships in multimodal data.

## üöÄ Quick Start

To quickly run a demo of the proposed method, simply execute:

```bash
pip install -r requirements.txt

python deep_learning_demo.py/tradition_demo.py
```

## üìñ Citation

If you find this work useful, please consider citing:

```bibtex
@article{Xiao2026AMVFC,
  author  = {Xiao, Luxi and Wang, Huajun and Ye, Chengming},
  title   = {Anchor-Guided Multi-View Fuzzy Clustering for Hyperspectral and LiDAR Images},
  journal = {Scientific Reports},
  year    = {2026},
  volume  = {16},
  pages   = {40213},
  doi     = {10.1038/s41598-026-40213-2},
  publisher = {Nature Publishing Group}
}
```





